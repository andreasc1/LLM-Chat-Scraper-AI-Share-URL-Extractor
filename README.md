# Live Chat Scraper â€“ AI Share URL Extractor  

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)  
[![Playwright](https://img.shields.io/badge/Playwright-Automation-green)](https://playwright.dev/)  
[![AI Vibe](https://img.shields.io/badge/Vibe%20Coded-AI-purple)](#)  

A Python tool that scrapes chat content from **live share URLs** of **ChatGPT, Claude, and Grok**.  

It first pulls URLs from the **Web Archive CDX API**:  

- `https://web.archive.org/cdx/search/cdx?url=chatgpt.com/share/*&output=txt&collapse=urlkey&fl=original&page=/`  
- `https://web.archive.org/cdx/search/cdx?url=https://claude.ai/share/*&output=txt&collapse=urlkey&fl=original&page=/`  
- `https://web.archive.org/cdx/search/cdx?url=grok.com/s/*&output=txt&collapse=urlkey&fl=original&page=/`  

Then it uses **Playwright** to open each live page, handle JavaScript-rendered content, strip out UI clutter, and save only the **clean chat messages** to a text file.  

âœ¨ Built for speed, simplicity, and fun â€“ and of course, **vibe coded using AI** ğŸ¤–  

---

## Features  
- ğŸ” Fetches share URLs from Web Archive CDX API  
- ğŸ“‚ Scrapes **ChatGPT**, **Claude**, and **Grok** share pages  
- ğŸ§¹ Filters out UI/boilerplate text, saving **only clean chat content**  
- ğŸ›ï¸ Interactive CLI: scrape **All**, a **Range**, or a **Number** of URLs  
- ğŸ•µï¸ Random User-Agents + delays to avoid detection  
- âš¡ Uses **Playwright** for robust JavaScript rendering  

---

## Installation  

1. Clone the repo:  
   ```bash
   git clone https://github.com/yourusername/live-chat-scraper.git
   cd live-chat-scraper
   ```
Install dependencies:

   ```bash
  pip install -r requirements.txt
  ```
  Install Playwright browsers (first-time setup only):
  ```bash
  playwright install
  Usage
  ```
Run the script:

  ```bash
  Copy code
  python scraper.py
  ```
Youâ€™ll be prompted to:

Select a source (ChatGPT, Claude, or Grok)

Choose whether to scrape All, a Range, or a Specific number of URLs

The script will fetch, scrape, and save results into a text file (e.g. scraped_content.txt).

Example
  ```
Fetching share URLs for ChatGPT...
âœ… Found 103347 URLs for ChatGPT.
Scrape (A)ll, (R)ange, or (N)umber? R
Enter range (1-103347): 888-891

ğŸ”¹ Scraping: https://chatgpt.com/share/714ea0c0-04b4-40e4-8c02-2e0059b4d854
âœ… Scraped successfully.

ğŸ”¹ Scraping: https://chatgpt.com/share/675489e9-36e8-800e-a8b8-0d4d296a0a6b
âœ… Scraped successfully.
  ```
The cleaned results are saved in:
  ```

scraped_content.txt
  ```

â­ If you found this useful, donâ€™t forget to star the repo!

